{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zalando_data_dir = \"/content/datasets/zalando/zalando\"\n",
    "def gentrainimages(path):\n",
    "    zalando_data_dir=path\n",
    "    train_images = tf.keras.utils.image_dataset_from_directory(\n",
    "        zalando_data_dir, label_mode=None, image_size=(64, 64), batch_size=32\n",
    "    )\n",
    "    train_images = train_images.map(lambda x: (x - 127.5) / 127.5)\n",
    "    return train_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent dimension of the random noise\n",
    "LATENT_DIM = 100 \n",
    "# weight initializer for G per DCGAN paper\n",
    "WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02) \n",
    "# number of channels, 1 for gray scale and 3 for color images\n",
    "CHANNELS = 3 # UPDATED from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    # create a Keras Sequential model \n",
    "    model = Sequential(name='generator')\n",
    "\n",
    "    # prepare for reshape: FC => BN => RN layers, note: input shape defined in the 1st Dense layer  \n",
    "    model.add(layers.Dense(8 * 8 * 512, input_dim=LATENT_DIM))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    # layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    # 1D => 3D: reshape the output of the previous layer \n",
    "    model.add(layers.Reshape((8, 8, 512)))\n",
    "\n",
    "    # upsample to 16x16: apply a transposed CONV => BN => RELU\n",
    "    model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    model.add((layers.ReLU()))\n",
    "\n",
    "    # upsample to 32x32: apply a transposed CONV => BN => RELU\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    model.add((layers.ReLU()))\n",
    "\n",
    "    # upsample to 64x64: apply a transposed CONV => BN => RELU\n",
    "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2),padding=\"same\", kernel_initializer=WEIGHT_INIT))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    model.add((layers.ReLU()))\n",
    "\n",
    "    # final layer: Conv2D with tanh activation\n",
    "    model.add(layers.Conv2D(CHANNELS, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "    # return the generator model\n",
    "    return model\n",
    "\n",
    "generator = build_generator() \n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(height, width, depth, alpha=0.2):\n",
    "    # create a Keras Sequential model\n",
    "    model = Sequential(name='discriminator')\n",
    "    input_shape = (height, width, depth)\n",
    "\n",
    "    # 1. first set of CONV => BN => leaky ReLU layers\n",
    "    model.add(layers.Conv2D(64, (4, 4), padding=\"same\", strides=(2, 2),\n",
    "        input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "    # 2. second set of CONV => BN => leacy ReLU layers\n",
    "    model.add(layers.Conv2D(128, (4, 4), padding=\"same\", strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "    # 3. third set of CONV => BN => leacy ReLU layers\n",
    "    model.add(layers.Conv2D(128, (4, 4), padding=\"same\", strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "    # flatten and apply dropout\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # sigmoid in the last layer outputting a single value for binary classification\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # return the discriminator model\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator(64, 64, 3) \n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Step 1. Train the discriminator with both real images (label as 1) and fake images (classified as label as 0) \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute discriminator loss on real images\n",
    "            pred_real = self.discriminator(real_images, training=True)\n",
    "            real_labels = tf.ones((batch_size, 1))\n",
    "            # UPDATED: apply one-sided label smoothing to real labels\n",
    "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels)) \n",
    "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
    "\n",
    "            # Compute discriminator loss on fake images\n",
    "            fake_images = self.generator(noise)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            # UPDATED: add random noise to fake labels - not needed\n",
    "            # fake_labels += 0.05 * tf.random.uniform(tf.shape(fake_labels)) \n",
    "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
    "\n",
    "            # total discriminator loss\n",
    "            d_loss = (d_loss_real + d_loss_fake)/2\n",
    "        # Compute discriminator gradients\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        # Update discriminator weights\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Step 2. Train the generator (do not update weights of the discriminator)\n",
    "        misleading_labels = tf.ones((batch_size, 1)) # G wants D to think the fake images are real (label as 1)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(noise, training=True)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            g_loss = self.loss_fn(misleading_labels, pred_fake)\n",
    "        # Compute generator gradients\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update generator wieghts\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=100):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Create random noise seed for visualization during traing\n",
    "        self.seed = tf.random.normal([16, latent_dim])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generator(self.seed)\n",
    "        generated_images = (generated_images * 127.5) + 127.5\n",
    "        generated_images.numpy()\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        for i in range(self.num_img):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            img = keras.utils.array_to_img(generated_images[i]) \n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        plt.savefig('epoc/epoch_{:03d}.png'.format(epoch)) \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.generator.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=LATENT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_LR = 0.0001 # UPDATED: discriminator learning rate\n",
    "G_LR = 0.0003 # UPDATED: generator learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=D_LR, beta_1 = 0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=G_LR, beta_1 = 0.5),  \n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sho(dir,NUM_EPOCHS):\n",
    "    train_images = tf.keras.utils.image_dataset_from_directory(\n",
    "        dir, label_mode=None, image_size=(64, 64), batch_size=32\n",
    "    )\n",
    "    train_images = train_images.map(lambda x: (x - 127.5) / 127.5)\n",
    "    dcgan.fit(train_images, epochs=NUM_EPOCHS, callbacks=[GANMonitor(num_img=16, latent_dim=LATENT_DIM)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sho(\"zalando\\zalando\\hoodies\",30000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
